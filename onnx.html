<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>onnx</title>
</head>

<body>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <h1>onnx</h1>
</body>
<script type="module">
    async function main() {
        try {
            // create a new session and load the specific model.
            const session = await ort.InferenceSession.create('data/sims.onnx');
            console.log('sims model loaded');

            // prepare inputs. a tensor need its corresponding TypedArray as data
            const batch_size = 8;
            const X = new ort.Tensor('float32', new Float32Array(batch_size*33694), [batch_size, 33694]); 
            for (let i = 0; i < 100; i++) {
                X.data[i] = 0.5;
            }

            // feed inputs and run
            const results = await session.run({"input.1": X});
            console.log('inference done');
            console.log(results);
            document.write(`<div>Cell 0 Predictions: ${results["826"].cpuData.slice(0,8)}</div>`);
        } catch (e) {
            document.write(`failed to inference ONNX model: ${e}.`);
        }
    }
    main();
    console.log('done');
</script>
</html>