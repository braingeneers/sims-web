{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98444189",
   "metadata": {},
   "source": [
    "# PUMAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d19523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from umap_pytorch import PUMAP\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d03ce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using accelerator: mps\n",
      "Sun Apr 27 20:24:01 2025 Building RP forest with 10 trees\n",
      "Sun Apr 27 20:24:02 2025 NN descent for 13 iterations\n",
      "\t 1  /  13\n",
      "\t 2  /  13\n",
      "\t 3  /  13\n",
      "\t 4  /  13\n",
      "\t 5  /  13\n",
      "\t 6  /  13\n",
      "\t 7  /  13\n",
      "\t 8  /  13\n",
      "\t 9  /  13\n",
      "\tStopping threshold met -- exiting after 9 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type            | Params\n",
      "--------------------------------------------\n",
      "0 | encoder | default_encoder | 87.4 K\n",
      "--------------------------------------------\n",
      "87.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "87.4 K    Total params\n",
      "0.350     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rcurrie/cell-space/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 11 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3738b2f4e44d7596925a80710dc3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n",
      "MPS is available. Using Apple Silicon GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "data = torch.randn((10000, 32))\n",
    "\n",
    "pumap = PUMAP(\n",
    "    encoder=None,  # nn.Module, None for default\n",
    "    decoder=None,  # nn.Module, True for default, None for encoder only\n",
    "    n_neighbors=10,\n",
    "    min_dist=0.1,\n",
    "    metric=\"euclidean\",\n",
    "    n_components=2,\n",
    "    beta=1.0,  # How much to weigh reconstruction loss for decoder\n",
    "    reconstruction_loss=torch.nn.functional.binary_cross_entropy_with_logits,  # pass in custom reconstruction loss functions\n",
    "    random_state=None,\n",
    "    lr=1e-3,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    num_workers=1,\n",
    "    num_gpus=1,\n",
    "    match_nonparametric_umap=False,  # Train network to match embeddings from non parametric umap\n",
    ")\n",
    "\n",
    "pumap.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655b682a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing array of shape torch.Size([10000, 32]) to (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "embedding = pumap.transform(data)  # (50000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358acbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09608545,  1.4405851 ],\n",
       "       [-1.2620441 ,  0.61724925],\n",
       "       [ 0.22486758, -0.16201767],\n",
       "       [ 0.13304317, -1.3588085 ],\n",
       "       [ 0.45416737,  2.266372  ],\n",
       "       [-0.6763597 , -0.6924829 ],\n",
       "       [ 0.77972907, -0.9883174 ],\n",
       "       [ 0.92042553, -1.5424372 ],\n",
       "       [ 1.1481138 , -2.1532557 ],\n",
       "       [-0.8550528 ,  0.7312847 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54754428",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "    pumap.model.encoder.encoder,\n",
    "    torch.zeros(1, data.shape[1]),\n",
    "    \"data/pumap_encoder.onnx\",\n",
    "    training=torch.onnx.TrainingMode.EVAL,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    export_params=True,\n",
    "    opset_version=12,\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a48a849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ort.InferenceSession(\"data/pumap_encoder.onnx\")\n",
    "onnx_embedding = session.run(\n",
    "    [\"output\"], {\"input\": data[0:10].to(torch.float32).detach().numpy()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c022b038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.09608544,  1.440585  ],\n",
       "        [-1.2620438 ,  0.6172491 ],\n",
       "        [ 0.22486767, -0.16201784],\n",
       "        [ 0.13304296, -1.3588084 ],\n",
       "        [ 0.4541675 ,  2.2663722 ],\n",
       "        [-0.67636   , -0.6924832 ],\n",
       "        [ 0.779729  , -0.9883174 ],\n",
       "        [ 0.9204255 , -1.5424374 ],\n",
       "        [ 1.1481137 , -2.153256  ],\n",
       "        [-0.8550529 ,  0.73128486]], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0426ec6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# if decoder enabled\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m recon \u001b[38;5;241m=\u001b[39m \u001b[43mpumap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (50000, 512)\u001b[39;00m\n",
      "File \u001b[0;32m~/cell-space/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/umap_pytorch/umap_pytorch/main.py:176\u001b[0m, in \u001b[0;36mPUMAP.inverse_transform\u001b[0;34m(self, Z)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverse_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, Z):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# if decoder enabled\n",
    "recon = pumap.inverse_transform(embedding)  # (50000, 512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
